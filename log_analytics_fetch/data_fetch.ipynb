{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant_id = dbutils.secrets.get(keyvault_name, 'tenant-id')\n",
    "client_id_log= dbutils.secrets.get(keyvault_name, 'adls-client-id')\n",
    "client_secret_log= dbutils.secrets.get(keyvault_name, 'adls-client-secret')\n",
    "workspace_id = dbutils.widget.get('log_workspace_id')\n",
    "env_name = dbutils.widget.get('env_name')\n",
    "\n",
    "custom_log = dbutils.widget.get('log_analytics_custom_log_name')\n",
    "\n",
    "water_mark_tab = dbutils.widget.get('delta_water_mark_table_name')\n",
    "now = datetime.now(timezone.utc)\n",
    "# Start time is one day before the current time\n",
    "start_time = now - timedelta(days=30)\n",
    "# End time is the current time\n",
    "end_time = now\n",
    "timespan = (start_time, end_time)\n",
    "\n",
    "log_it = Log_fetch(tenant_id,client_id_log,client_secret_log,workspace_id,timespan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting max of uid value from the watermark table\n",
    "max_last_uid = get_max_uid('custom_log_name',water_mark_tab,env_name)\n",
    "\n",
    "# KQL - using which we want to extract data from the Log Analytics Custom Log\n",
    "# We have constructed MetadataLogGuid column in all Log Analytics Custom Log tables\n",
    "# It is in format of yyMMddhh000000001 - yyMMddhh999999999\n",
    "query_base = f\"\"\"{custom_log}\n",
    "| extend uid = todecimal(MetadataLogGuid)\n",
    "| order by uid asc\n",
    "| where uid>todecimal('{max_last_uid}')\n",
    "\"\"\"\n",
    "# Getting information about how many data is needed to be read and downloaded which is greater than max_last_uid value.\n",
    "iteration_counter = log_it.fetch_log_gt_xuid_cnt(query_base)\n",
    "divider = dbuitls.widget.get('number_of_records')\n",
    "iterate = Math.ciel(iteration_counter/divider)\n",
    "\n",
    "for i in range(iterate):\n",
    "    max_last_uid = get_max_uid('custom_log_name',water_mark_tab,env_name)\n",
    "    # we can add the where and project clause too to extract desired data and columns\n",
    "    query_base = f\"\"\"{custom_log}\n",
    "| extend uid = todecimal(MetadataLogGuid)\n",
    "| order by uid asc\n",
    "| where uid> todecimal('{max_last_uid}')\n",
    "| take {divider}\n",
    "\"\"\"\n",
    "    response_data = log_it.fetch_logs(query_base)\n",
    "    if response_data == 'Response Fail':\n",
    "        print('Response Failed, Please check and try later')\n",
    "        break\n",
    "    else:\n",
    "        for table in response_data:\n",
    "            df = pd.Dataframe(data=table.rows,columns=table.columns)\n",
    "    sparkDF = spark.createDataFrame(df)\n",
    "    sparkDF.createOrReplaceTempView('df_data_view')\n",
    "    data_max_uid_df = spark.sql('select max(uid) as uid_max from df_data_view')\n",
    "    data_max_uid_df = data_max_uid_df.withColumn('log_name',F.lit(custom_log)).withColumn('env_name',F.lit(env_name))\n",
    "\n",
    "    merge_into(data_max_uid_df,water_mark_tab,env_name)\n",
    "    raw_path = f'abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{custom_log}/{env_name}'\n",
    "    sparkDF.write.format('json').mode('append').save(raw_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
